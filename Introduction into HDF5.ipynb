{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- Main features of HDF5\n",
    "- Overview: Packages for HDF5 with Python\n",
    "  + h5py\n",
    "  + pytables\n",
    "  + pandas\n",
    "  + xarray\n",
    "  \n",
    "Notebooks here: https://github.com/mcrot/meetup-python-hdf5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# HDF5: **H**ierachical **D**ata **F**ormat Version **5**\n",
    "\n",
    "*HDF5* used as term for three things:\n",
    "\n",
    "- file format\n",
    "- data model \n",
    "- software (libraries, tools, interfaces for many languages)\n",
    "\n",
    "Features:\n",
    "\n",
    "- storage of large amounts of (scientific) data\n",
    "- data structures often used in science (arrays, images, ..)\n",
    "- rich set of data types including composite and user-defined data types\n",
    "- hierachical structure \n",
    "- including metadata ($\\rightarrow$ *self-describing*)\n",
    "- compressed\n",
    "- binary, platform-independet\n",
    "- easily sharable\n",
    "- *old* reliable technology\n",
    "- open source (BSD-style)\n",
    "\n",
    "# Data Model\n",
    "\n",
    "HDF5 is not only a file format but also a data model.\n",
    "\n",
    "https://support.hdfgroup.org/HDF5/Tutor/HDF5Intro.pdf\n",
    "\n",
    "Two primary types of objects (many other):\n",
    "  \n",
    "1. Groups\n",
    "\n",
    "   - HDF5 file itself is a group\n",
    "   - can hold other groups, links to other elements and \n",
    "     *datasets*\n",
    "   \n",
    "2. Datasets\n",
    "\n",
    "   - $n$-dimensional array of elements with metadata,\n",
    "     each element of the dataset may be a complex object itself\n",
    "\n",
    "\n",
    "# File Format\n",
    " \n",
    "Specification of file format is complex, more than 150 pages. \n",
    "\n",
    "https://support.hdfgroup.org/HDF5/doc/Specs.html\n",
    "\n",
    "In pratice one implementation, written in C, by HDF Group.\n",
    "In general a user can work with libraries instead.\n",
    "\n",
    "\n",
    "# HDF Group\n",
    "\n",
    "- starting in the 80's\n",
    "- 18 Years at University of Illinois National Center\n",
    "for Supercomputing Applications (NCSA)\n",
    "- Spun-out from NCSA in July, 2006\n",
    "- Non-profit organisation\n",
    "- Intellectual property:\n",
    "  + The HDF Group owns HDF4 and HDF5\n",
    "  + HDF formats and libraries to remain open\n",
    "  + BSD-style license \n",
    "\n",
    "## Mission Statement\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   To ensure long-term accessibility of HDF\n",
    "   data through sustainable development\n",
    "   and support of HDF technologies. \n",
    "</div>\n",
    "\n",
    "More:\n",
    "\n",
    " https://www.hdfgroup.org/the-hdf-group-mission/\n",
    "\n",
    "\n",
    "## Users\n",
    "\n",
    "List of HDF5 Group\n",
    "\n",
    "    https://support.hdfgroup.org/HDF5/users5.html\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What means *large*?\n",
    "\n",
    "- in principle, no limits on file size (according to *HDF Group*)\n",
    "- a single dataset is limited, but currently not in practice:\n",
    "\n",
    "  > The library currently allows up to 32 dimension dataspaces, and \n",
    "  > each dimension can have up to an unsigned 64-bit value. Each \n",
    "  > datatype can be somewhat arbitrarily large, since you can have \n",
    "  > array datatypes or compound datatypes that are very large.\n",
    "  > Multiplying those two factors together gives a theoretical upper \n",
    "  > limit probably in the thousands of bits of for a dataset's size.  \n",
    "  > However, the library currently only supports 64-bit offsets \n",
    "  > (although that is easily adjustable when files over 16 exabytes are   > needed!), so that is the practical upper limit.\n",
    "   \n",
    "  https://support.hdfgroup.org/HDF5/faq/limits.html\n",
    "  \n",
    "  https://en.wikipedia.org/wiki/Exabyte\n",
    "  \n",
    "- heavy use in NASA's Earth Observing System (*EOS*) project:    \n",
    " \n",
    "    http://hdfeos.org/\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Critics\n",
    "\n",
    "Discussion about HDF5:\n",
    "\n",
    " http://cyrille.rossant.net/moving-away-hdf5/\n",
    " \n",
    "Answer of Konrad Hinsen:\n",
    "\n",
    " http://blog.khinsen.net/posts/2016/01/07/on-hdf5-and-the-future-of-data-management/\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
